{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d2kLrOh-bpGy"
   },
   "source": [
    "# Iris Flower Classification with Scikit-Learn\n",
    "\n",
    "![Iris](https://github.com/featurestoreorg/serverless-ml-course/raw/main/src/01-module/assets/iris.png)\n",
    "\n",
    "\n",
    "In this notebook we will, \n",
    "\n",
    "1. Synthetic data generation for Iris Flowers\n",
    "2. Split trainind data into train and test sets (one set each for features and labels)\n",
    "3. Encode the label\n",
    "4. Train a KNN Model using SkLearn\n",
    "5. Evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "nRmFM7vcbpHA",
    "outputId": "d920d168-9818-40c5-c292-4cf0afcbbcfd"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def generate_flower(name, sepal_len_max, sepal_len_min, sepal_width_max, sepal_width_min, \n",
    "                    petal_len_max, petal_len_min, petal_width_max, petal_width_min):\n",
    "    columns = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]\n",
    "    flower = []\n",
    "    flower.append(random.uniform(sepal_len_max, sepal_len_min))\n",
    "    flower.append(random.uniform(sepal_width_max, sepal_width_min))\n",
    "    flower.append(random.uniform(petal_len_max, petal_len_min))\n",
    "    flower.append(random.uniform(petal_width_max, petal_width_min))\n",
    "    df = pd.DataFrame(flower,columns)\n",
    "    df['variety'] = name\n",
    "    return flower\n",
    "\n",
    "\n",
    "virginica_df = generate_flower(\"virginica\" 6, 4.5, 3.8, 2.2, 7, 4.5, )\n",
    "versicolor_df = generate_flower(\"versicolor\", 8, 5.5, 3.5, 2.5, 2, 1, )\n",
    "setosa_df =  generate_flower(\"setosa\", 7, 5, 4.5, 2.5, 5, 3.5, )\n",
    "\n",
    "# randomly pick one of these 3 and write it to the featurestore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that our 3 different classes of iris flowers have different *petal_lengths* \n",
    "(although there are some overlapping regions between Versicolor and the two other varieties (Setoas, Virginica))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the DataFrame into 2: one DataFrame containing the *features* and one containing the *labels*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tTAvavFkG5dX",
    "outputId": "775c9848-b4b7-42ff-c950-e8bc5302683c"
   },
   "outputs": [],
   "source": [
    "features = iris_df[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]\n",
    "labels = iris_df[[\"variety\"]]\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can split our features and labels into a **train_set** and a **test_set**. You split your data into a train_set and a test_set, because you want to train your model on only the train_set, and then evaluate its performance on data that was not seen during training, the test_set. This technique helps evaluate the ability of your model to accurately predict on data it has not seen before.\n",
    "\n",
    "This looks as follows:\n",
    "\n",
    "* **X_** is a vector of features, so **X_train** is a vector of features from the **train_set**. \n",
    "* **y_** is a scale of labels, so **y_train** is a scalar of labels from the **train_set**. \n",
    "\n",
    "Note: a vector is an array of values and a scalar is a single value.\n",
    "\n",
    "Note: that mathematical convention is that a vector is denoted by an uppercase letter (hence \"X\") and a scalar is denoted by a lowercase letter (hence \"y\").\n",
    "\n",
    "**X_test** is the features and **y_test** is the labels from our holdout **test_set**. The **test_set** is used to evaluate model performance after the model has been trained.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JR8HeEs6bpHB"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(features, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do some **Feature Engineering**. \n",
    "\n",
    "We will transform the label from a categorical variable (a string) into a numerical variable (an int). Many machine learning training algorithms only take numerical values as inputs for training (and inference).\n",
    "\n",
    "We can see that our original lables (**y_train** and **y_test**) are categorical variables. We will use Scikit-Learn's **LabelEncoder** to transform the strings into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KJb2bj-_bpHD",
    "outputId": "8dc9bade-60b0-476e-860e-f89ab2ded962"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "y_train_encoded=le.fit_transform(y_train['variety'])\n",
    "y_test_encoded = le.transform(y_test['variety'])\n",
    "y_test.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that **y_test_encoded** has been transformed into a numerical variable (an int). **y_train_encoded** has been similarly transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_encoded[0:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit a model to our features and labels from our training set (**X_train** and **y_train_encoded**). Fitting a model to a dataset is more commonly called \"training a model\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PNZcUPHJPIu9",
    "outputId": "389acb4d-74ff-46f1-dee8-a7c27ee79a09"
   },
   "outputs": [],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=4)\n",
    "model.fit(X_train, y_train_encoded) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have trained our model. We can evaluate our model on the **test_set** to estimate its performance.\n",
    "Notice that the model was trained to output the encoded labels (numbers)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uHuAD3ttP8Ep"
   },
   "outputs": [],
   "source": [
    "y_pred_encoded = model.predict(X_test)\n",
    "y_pred_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the predicted flower names by inverse transforming our numerical predictions back into their original string form. To perform the inverse transform, we need the **le** (LabelEncoder) object used to perform the orginal categorical to numerical mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le.inverse_transform(y_pred_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can report on how accurate these predictions (**y_pred_encoded**) are compared to the labels (the actual results - **y_test_encoded**). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b8EC4_SvbpHE",
    "outputId": "5d73b375-76f0-4518-8e88-4db23e8f2486"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "metrics = classification_report(y_test_encoded, y_pred_encoded)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J1qSq_yNPYsO",
    "outputId": "11f09c2a-0a05-4592-f2d3-973eccc71d31"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "results = confusion_matrix(y_test_encoded, y_pred_encoded)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "# Setosa = 0, Versicolor = 1, Virginica = 2\n",
    "\n",
    "df_cm = pd.DataFrame(results, ['True Setosa', 'True Versicolor', 'True Virginica'],\n",
    "                     ['Pred Setosa', 'Pred Versicolor', 'Pred Virginica'])\n",
    "\n",
    "sns.heatmap(df_cm, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homework task\n",
    "\n",
    "Rewrite the last two cells, but instead of computing the *classification_report* and the *confusion_matrix* with the encoded labels, use the unencoded labels. \n",
    "\n",
    "Are the results the same? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "predictions_untransformed = le.inverse_transform(y_pred_encoded)\n",
    "results = confusion_matrix(y_test, predictions_untransformed)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gradio --quiet\n",
    "!pip install typing-extensions==4.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def iris(sl, sw, pl, pw):\n",
    "    input_list = []\n",
    "    input_list.append(sl)\n",
    "    input_list.append(sw)\n",
    "    input_list.append(pl)\n",
    "    input_list.append(pw)\n",
    "    res = model.predict(np.asarray(input_list).reshape(1, -1)) \n",
    "    # Convert the numerical representation of the label back to it's original iris flower name.\n",
    "    # le.inverse_transform returns a list of flower names with only 1 entry, so we add '[0]' to \n",
    "    # the list returned by le.inverse_transform(..) to return only the iris flower name (not the list)\n",
    "    return le.inverse_transform(res)[0]\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=iris,\n",
    "    title=\"Iris Flower Predictive Analytics\",\n",
    "    description=\"Experiment with sepal/petal lengths/widths to predict which flower it is.\",\n",
    "    allow_flagging=\"never\",\n",
    "    inputs=[\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"sepal width (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal length (cm)\"),\n",
    "        gr.inputs.Number(default=1.0, label=\"petal width (cm)\"),\n",
    "        ],\n",
    "    outputs=\"text\")\n",
    "\n",
    "demo.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
