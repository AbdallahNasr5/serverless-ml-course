{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9411b6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credit_card_number</th>\n",
       "      <th>trans_datetime</th>\n",
       "      <th>amount</th>\n",
       "      <th>location</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-01 08:44:00</td>\n",
       "      <td>142.34</td>\n",
       "      <td>Sao Paolo</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 19:44:00</td>\n",
       "      <td>12.34</td>\n",
       "      <td>Rio De Janeiro</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:44:00</td>\n",
       "      <td>66.29</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1111 2222 3333 4444</td>\n",
       "      <td>2022-01-02 20:55:00</td>\n",
       "      <td>112.33</td>\n",
       "      <td>Stockholm</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    credit_card_number      trans_datetime  amount        location  fraud\n",
       "0  1111 2222 3333 4444 2022-01-01 08:44:00  142.34       Sao Paolo  False\n",
       "1  1111 2222 3333 4444 2022-01-02 19:44:00   12.34  Rio De Janeiro  False\n",
       "2  1111 2222 3333 4444 2022-01-02 20:44:00   66.29       Stockholm   True\n",
       "3  1111 2222 3333 4444 2022-01-02 20:55:00  112.33       Stockholm   True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = { \n",
    "    'credit_card_number': ['1111 2222 3333 4444', '1111 2222 3333 4444','1111 2222 3333 4444',\n",
    "                           '1111 2222 3333 4444'],\n",
    "    'trans_datetime': ['2022-01-01 08:44', '2022-01-02 19:44', '2022-01-02 20:44', '2022-01-02 20:55'],\n",
    "    'amount': [142.34, 12.34, 66.29, 112.33],\n",
    "    'location': ['Sao Paolo', 'Rio De Janeiro', 'Stockholm', 'Stockholm'],\n",
    "    'fraud': [False, False, True, True] \n",
    "}\n",
    "\n",
    "df = pd.DataFrame.from_dict(data)\n",
    "df['trans_datetime']= pd.to_datetime(df['trans_datetime'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c855e3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected. Call `.close()` to terminate connection gracefully.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/398\n",
      "Connected. Call `.close()` to terminate connection gracefully.\n"
     ]
    }
   ],
   "source": [
    "import hopsworks\n",
    "proj = hopsworks.login()\n",
    "fs = proj.get_feature_store()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d38175",
   "metadata": {},
   "source": [
    "### Create a Feature Group\n",
    "\n",
    "Hopsworks have comprehensive documentation on Feature Groups. Click on these links to learn more.\n",
    "\n",
    "* [Feature Group Concept](https://docs.hopsworks.ai/3.0/concepts/fs/feature_group/fg_overview/)\n",
    "* [Feature Group Creation Guide](https://docs.hopsworks.ai/3.0/user_guides/fs/feature_group/create/)\n",
    "* [Feature Group API Docs](https://docs.hopsworks.ai/feature-store-api/3.0/generated/api/feature_group_api/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ea7a88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_transactions\",\n",
    "     version=1,\n",
    "     description=\"Credit Card Transaction data\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='trans_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990c0972",
   "metadata": {},
   "source": [
    "### Write your DataFrame to the Feature Group\n",
    "When you write your DataFrame to the feature group, first the DataFrame is copied to Hopsworks. \n",
    "Then a backfill ingestion job is run on Hopsworks to insert/append the DataFrame to the Feature Group. \n",
    "The job is a Spark job, and the data is stored in a Apache Hudi table in Hopsworks.\n",
    "\n",
    "It will take about 1 minute for the ingestion job to complete.\n",
    "If you don't want to wait 1 minute, you make the ingestion job run in the background with:\n",
    "\n",
    "\n",
    "    fg.insert(df, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3380610c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Group created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/398/fs/335/fg/1364\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb7d01100d864cbd9585ef4fb4793c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading Dataframe: 0.00% |          | Rows 0/4 | Elapsed Time: 00:00 | Remaining Time: ?"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching offline feature group backfill job...\n",
      "Backfill Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai/p/398/jobs/named/credit_card_transactions_1_offline_fg_backfill/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<hsfs.core.job.Job at 0x7feaa70a2df0>, None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fg.insert(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12edd509",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fg.select([\"amount\", \"location\", \"fraud\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac7e3a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature view created successfully, explore it at \n",
      "https://c.app.hopsworks.ai:443/p/398/fs/335/fv/credit_card_transactions/version/1\n"
     ]
    }
   ],
   "source": [
    "fv = fs.create_feature_view(name=\"credit_card_transactions\",\n",
    "                            version=1,\n",
    "                            description=\"Features from the credit_card_transactions FG\",\n",
    "                            labels=[\"fraud\"],\n",
    "                            query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "792da473",
   "metadata": {},
   "outputs": [
    {
     "ename": "RestAPIError",
     "evalue": "Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/featurestores/335/featureview/credit_card_transactions/version/1/trainingdatasets). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"type\":\"restApiJsonResponse\",\"errorCode\":120000,\"errorMsg\":\"A generic error occurred.\"}', error code: 120000, error msg: A generic error occurred., user msg: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRestAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2755595/1011284238.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/feature_view.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(self, test_size, train_start, train_end, test_start, test_end, description, extra_filter, statistics_config, read_options)\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mextra_filter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextra_filter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m         )\n\u001b[0;32m--> 775\u001b[0;31m         td, df = self._feature_view_engine.get_training_data(\n\u001b[0m\u001b[1;32m    776\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0mread_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py\u001b[0m in \u001b[0;36mget_training_data\u001b[0;34m(self, feature_view_obj, read_options, splits, training_dataset_obj, training_dataset_version)\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_event_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_view_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             td_updated = self._create_training_data_metadata(\n\u001b[0m\u001b[1;32m    179\u001b[0m                 \u001b[0mfeature_view_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/core/feature_view_engine.py\u001b[0m in \u001b[0;36m_create_training_data_metadata\u001b[0;34m(self, feature_view_obj, training_dataset_obj)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_create_training_data_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_view_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m         td = self._feature_view_api.create_training_dataset(\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0mfeature_view_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_view_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_dataset_obj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m         )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/core/feature_view_api.py\u001b[0m in \u001b[0;36mcreate_training_dataset\u001b[0;34m(self, name, version, training_dataset_obj)\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"content-type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"application/json\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         return training_dataset_obj.update_from_response_json(\n\u001b[0;32m--> 141\u001b[0;31m             self._client._send_request(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0;34m\"POST\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_dataset_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/decorators.py\u001b[0m in \u001b[0;36mif_connected\u001b[0;34m(inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_connected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNoHopsworksConnectionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mif_connected\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/hsfs/client/base.py\u001b[0m in \u001b[0;36m_send_request\u001b[0;34m(self, method, path_params, query_params, headers, data, stream, files)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRestAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRestAPIError\u001b[0m: Metadata operation error: (url: https://c.app.hopsworks.ai/hopsworks-api/api/project/398/featurestores/335/featureview/credit_card_transactions/version/1/trainingdatasets). Server response: \nHTTP code: 500, HTTP reason: Internal Server Error, body: b'{\"type\":\"restApiJsonResponse\",\"errorCode\":120000,\"errorMsg\":\"A generic error occurred.\"}', error code: 120000, error msg: A generic error occurred., user msg: "
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = fv.train_test_split(0.5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506debf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0ef527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6599bb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24722f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f6d416",
   "metadata": {},
   "source": [
    "### Aggregations\n",
    "\n",
    "Compute the total amount spent on the credit card by first grouping all the rows together with the same `credit_card_number` and then summing up their amounts. \n",
    "\n",
    "The code first creates a new DataFrame with only the `credit_card_number` and `amount` columns, then the logic of a group-by could be described as \n",
    "\n",
    "    for-each (`credit_card_number`) do \\sigma amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4be1e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[[\"credit_card_number\", \"amount\"]].groupby(\"credit_card_number\").sum()\n",
    "df2.rename(columns={\"amount\": \"total_spent\"}, inplace=True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0be838",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d187468e",
   "metadata": {},
   "source": [
    " We might also want to know at what point-in-time was that total and add a column with the datetime of the last (most recent) credit card transaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04244e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[\"as_of_datetime\"] = df[[\"credit_card_number\", \"trans_datetime\"]].groupby(\"credit_card_number\").max()\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad27a872",
   "metadata": {},
   "source": [
    "The `groupby` operation sets `credit_card_number` as the index of our DataFrame.\n",
    "We want `credit_card_number` as a column, as Pandas indexes are not written to the Feature Group.\n",
    "We can move the index to a column using `reset_index`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec0104f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.reset_index(inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8253595",
   "metadata": {},
   "source": [
    "We create a feature group to store the contents of `df2` with our aggregated credit card spending information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c321ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg2 = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_spending\",\n",
    "     version=1,\n",
    "     description=\"Credit Card Spending\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='as_of_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712f283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg2.insert(df2, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b7aedf",
   "metadata": {},
   "source": [
    "Let's add some more data to our original feature group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac3a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_data = { \n",
    "    'credit_card_number': ['9999 8888 7777 6666', '9999 8888 7777 6666','9999 8888 7777 6666',\n",
    "                           '9999 8888 7777 6666'],\n",
    "    'trans_datetime': ['2022-01-02 04:11', '2022-01-03 07:24', '2022-01-05 10:33', '2022-01-05 11:50'],\n",
    "    'amount': [55.67, 84, 77.95, 183],\n",
    "    'location': ['San Francisco', 'San Francisco', 'Dublin', 'Dublin'],\n",
    "    'fraud': [False, False, False, False] \n",
    "}\n",
    "\n",
    "df3 = pd.DataFrame.from_dict(more_data)\n",
    "df3['trans_datetime']= pd.to_datetime(df3['trans_datetime'])\n",
    "\n",
    "fg = fs.get_feature_group(name=\"credit_card_transactions\", version=1)\n",
    "\n",
    "fg.insert(df3, write_options={\"wait_for_job\": False})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1d883",
   "metadata": {},
   "source": [
    "Now let's compute how much money was spent on the card since the last time we computed amount spent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4943b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95cbb39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['is_big'] = df['amount'].apply(lambda amount: amount > 100)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2edb1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_small(row):\n",
    "    return row['amount'] < 100\n",
    "\n",
    "df4['is_small'] = df.apply(is_small, axis=1)\n",
    "\n",
    "df4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a2dc55",
   "metadata": {},
   "source": [
    "## Time Series: Window Aggregations\n",
    "\n",
    "Count the amount of money spent per day (make the length of the window '1d').\n",
    "We will need to set the `event_time` column as the index in order to use Pandas built-in window aggregations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2baba5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = fg.read()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864dc8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.set_index('trans_datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b325eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51e0b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['rolling_max_1d'] = df5.rolling('1D').amount.max()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dec426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['rolling_mean_1d'] = df5.rolling('1D').amount.mean()\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683a0337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114b74d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_agg = fs.get_or_create_feature_group(\n",
    "     name=\"credit_card_rolling_windows\",\n",
    "     version=1,\n",
    "     description=\"Daily Credit Card Spending\",\n",
    "     primary_key=['credit_card_number'],\n",
    "     event_time='trans_datetime'\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b05b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_agg.insert(df5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31174a83",
   "metadata": {},
   "source": [
    "### Create a Feature View using features from multiple Feature Groups\n",
    "\n",
    "We want to create a model that uses features from multiple feature groups. \n",
    "We will select features from the different feature groups and join them together to create a query object. \n",
    "We can read the data in the query object as a DataFrame to inspect it before we create the feature view. \n",
    "We will use the feature view to read the training data for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf25f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = fg.select_all().join(fg_agg.select(['rolling_max_1d', 'rolling_mean_1d']))\n",
    "\n",
    "training_data = query.read()\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa4cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = fs.create_feature_view(name=\"credit_card_fraud_rolling\",\n",
    "                            description=\"Features for a model to predict credit card fraud, including rolling windows\",\n",
    "                            version=1,\n",
    "                            query=query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6e33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = fv.train_test_split(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dae8969",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1c67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1717fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fg = fs.get_feature_group(name=\"credit_card_transactions\", version=1)\n",
    "read_df = fg.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67029b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d028c469",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034e02a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
